\IEEEtitleabstractindextext{
    \begin{abstract}
        %NOTE: (1) random latency matters; why random latency matters;
        Random transmission latency is appeared as a non-negligible issue in edge computing system when considering distributed scheduler implementation in a large network such as Metropolitan Area Network (MAN).
        With the random latency of information sharing among distributed schedulers, the shared system status information would inevitably become stale and thus deviates the optimality. %drift away from optimality.
        %NOTE: (2) online/distributed/cooperative/job dispatching/outdated information
        In this paper, we investigate an online distributed cooperative job dispatching problem in an edge computing system residing in a MAN, where multiple access points (APs) collect jobs from the mobile users and upload each job to one edge server for computation.
        %NOTE: (3) the signaling mechanism (information sharing); partial information;
        Furthermore, we introduce a signaling mechanism to facilitate information sharing among distributed schedulers on each AP.
        % with periodic broadcast to facilitate cooperations among APs.
        % we design the broadcast mechanism and extend to a general partial information practice with partial information, in the distributed system design.
        Moreover, the fully-observed system state is discouraged as reception of all broadcast is time consuming.
        The signaling and job dispatching latency is random and non-negligible in MAN, and the APs have to update their job dispatching strategies according to partially received and outdated broadcast information.
        %NOTE: (4) technical contribution: we leverage POMDP to formulate this {long-term dynamic} problem, and design a {delicate} low-complexity framework, and extend it to unknown-priori scenario via a novel reinforcement learning framework.
        We formulate the distributed optimization of job dispatching strategies at all the APs, with partial and outdated information, as a partially observable Markov decision process (POMDP).
        %whose minimization objective is a discounted measurement of job delivery and computation time.
        % The conventional solution for POMDP is impractical due to huge time complexity.
        % In this paper, we propose a novel low-complexity solution framework for distributed job dispatching.
        % Based on it, the optimization of job dispatching policy can be decoupled via an \emph{alternative policy iteration algorithm}, called \algname, so that the distributed policy iteration of each AP can be made according to partial and outdated observation.
        % An analytical performance lower bound is provided for the approximate MDP solution.
        Furthermore, we extend \algname~to handle a more general scenario where the statistics of job arrivals, uploading latency and job processing time are unknown.
        The extended \algname~leverages a novel and efficient reinforcement learning approach to online continuously improve the system performance.
        % NOTE: (5) the simulation and performance improvement
        % Finally, we conduct extensive simulations based on the Google Cluster trace.
        % The evaluation results show that our policy can achieve as high as $20.67\%$ reduction in average job response time compared with heuristic baselines, and our algorithm consistently performs well under various parameter settings.
    \end{abstract}

    % Note that keywords are not normally used for peer-review papers.
    \begin{IEEEkeywords}
        Edge computing, metropolitan area network, partially-observable MDP, reinforcement learning.
    \end{IEEEkeywords}
}
