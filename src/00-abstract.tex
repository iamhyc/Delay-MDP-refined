\IEEEtitleabstractindextext{
    \begin{abstract}
        In this paper, we investigate online distributed job dispatching in an edge computing system residing in a Metropolitan Area Network (MAN).
        Specifically, multiple access points (APs) collect jobs from the mobile users, and upload each job to one edge server for computation. A signaling mechanism with periodic broadcast is introduced to facilitate cooperation among APs.
        The signaling and job dispatching latency is random and non-negligible in MAN, and the APs have to update their job dispatching strategies according to partially received and outdated broadcast information.
        % Moreover, the fully-observed system state is discouraged as reception of all broadcast is time consuming.
        Therefore, we formulate the distributed optimization of job dispatching strategies at all the APs as a partially observable Markov decision process (POMDP), whose minimization objective is a discounted measurement of job delivery and computation time.
        The conventional solution for POMDP is impractical due to huge time complexity.
        In this paper, we propose a novel low-complexity solution framework for distributed job dispatching.
        Based on it, the optimization of job dispatching policy can be decoupled via an \emph{alternative policy iteration algorithm}, called \algname, so that the distributed policy iteration of each AP can be made according to partial and outdated observation.
        An analytical performance lower bound is provided for the approximate MDP solution.
        \hongyc{
            Furthermore, we extend \algname~to handle a more general scenario where the statistics of job arrivals, uploading latency and job processing time are unknown.
            The extended \algname~leverages a novel and efficient reinforcement learning approach to online continuously improve the system performance.
        }
        Finally, we conduct extensive simulations based on the Google Cluster trace.
        The evaluation results show that our policy can achieve as high as $20.67\%$ reduction in average job response time compared with heuristic baselines, and our algorithm consistently performs well under various parameter settings.
    \end{abstract}

    % Note that keywords are not normally used for peer-review papers.
    \begin{IEEEkeywords}
        Edge computing, metropolitan area network, partially-observable MDP, reinforcement learning.
    \end{IEEEkeywords}
}
