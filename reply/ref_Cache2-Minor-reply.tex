\documentclass[12pt,onecolumn]{IEEEtran}


\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{stfloats}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{psfrag}
%\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{array}
\usepackage{epstopdf}
\usepackage{authblk}
\usepackage{graphicx} 
\usepackage{amsthm} 
\usepackage{lipsum}
\usepackage{verbatim} 
\usepackage{color}
\usepackage{caption}
\usepackage{subcaption}

\newcommand{\blue}{\color{blue}}
\newcommand{\black}{\color{black}}
\newcommand{\red}{\color{red}}

\usepackage{graphicx}
\newcommand{\spaceblank}{\vskip 4mm}

\renewcommand{\baselinestretch}{1.4}

\newtheorem{Definition}{Definition}
\newtheorem{Problem}{Problem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Theorem}{Theorem}
\newtheorem{Algorithm}{Algorithm}
\newtheorem{Policy}{Policy}
\newtheorem{Scheme}{Scheme}
\newtheorem{Scenario}{Scenario}
\newtheorem{Assumption}{Assumption}
\newtheorem{Proposition}{Proposition}
\newtheorem{Remark}{Remark}
\newtheorem{Solution}{Solution}
\newtheorem{Baseline}{Baseline}
\newtheorem{Example}{Example}
\newtheorem{Corollary}{Corollary}
\newtheorem{Model}{Model}

\begin{document}
\title{Reply to the Editor and Reviewers' Comments on Manuscript ID TCOM-TPS-19-0440.R1}

\author{}
\maketitle

We thank the editor and reviewers for all the constructive comments. They have helped to improve the technical accuracy and presentation of the manuscript. In the revised manuscript, the main changes are emphasized in {\blue blue} for the reading convenience.

In this reply file, we first state the comments in {\em \black italics and black}, and then respond to them in {\color{blue}blue}. Unless mentioned otherwise, the equation, figure and citation numbers refer to those in this reply file.


\section{Response to Editor}
\spaceblank

{\blue
	We are thankful to Editor for the constructive comments, which help to improve the paper. We now address the specific comments below.
}

\spaceblank
\noindent{\em \textbf{Comment 1:} 
The quasi-static and the i.i.d. fading assumption (raised by reviewer 2) is rather common, and it is OK.
}
\spaceblank
	
{\blue \textbf{Response E-1:} 
	Thank you for the comment. 
}

\spaceblank
\noindent{\em \textbf{Comment 2:}
	Since this paper does not deal with delay, given the use of the ergodic capacity expression, it is OK too. 
}
\spaceblank
{\blue \textbf{Response E-2:} 
	Thank you for the comment. 
}
\spaceblank
\noindent{\em \textbf{Comment 3.1:}
Reviewer 3 raised a question regarding the number of users, which is directly related to beta defined on page 6. 
}
\spaceblank

\begin{figure}[tb]
	\centering
	\includegraphics[scale = 0.72]{cost_pr.eps} %Sim_request_num.eps
	\caption{The average total cost versus the expectation of request times, where $\gamma=1.2$,  $\frac{M_c}{M_F}=0.6$ ($\forall c$).}
	\label{fig:request}
\end{figure}

{\blue \textbf{Response E-3.1:} 
	Thank you for the comment. 	 Since we consider random arrivals of requesting users, the  impact of user arrival rate (as well as the average user number) is considered in simulation. 
	Specifically, the average transmission cost versus the average number of file requests (requesting users) in the whole lifetime $\beta T$ is illustrated in Fig. \ref{fig:request} (Fig. 4 (a) of the revised manuscript). It can be observed that the proposed scheme consumes less transmission resource than the baselines. Moreover, the average cost increases with the arrival rate of requesting users. This is because cache nodes cannot serve all the cell coverage area or store all the popular files, and some file transmissions have to rely on the BS.
}


\spaceblank
\noindent{\em \textbf{Comment 3.2:}
I noticed that there is no hard power constraint in the optimisation problem (which is
	unusual). 
}
\spaceblank


{\blue \textbf{Response E-3.2:} 
	Thank you for the comment. 	The following peak (hard) multicast power constraint at the BS has been added in the revised manuscript (equation (1)), 
	\begin{align}
	P_{\tau}\leq P_B, \forall \tau,
	\end{align}
	where $P_B$ is the maximum transmission power for each file multicast at the BS. Due to new peak power constraint, Section II, III, IV, V and VI of the manuscript have been revised accordingly. Moreover, we have also regenerated simulation results.
}
\spaceblank
\noindent{\em \textbf{Comment 3.3:}
	 There is also no hard constraint on the file delivery (do you need to delivery the file
	eventually?). Please include a more thorough, higher-level description of the problem/aim in Section
	III.A. What exactly you want to optimise? Is this a best effort delivery? The statement "we shall
	minimize the transmission resource consumption" seems to be a desirable thing to do to "maximize
	delivery of dedicated data". If that's the case, why don't we maximize "delivery of dedicated data"
	directly? If we want to minimise the resources, then can we just simply don't transmit?
}
\spaceblank



{\blue \textbf{Response E-3.3:} 
Thank you for the comment. There might be some misunderstanding on our problem. 
	In fact, there is a hard constraint on the file delivery in this paper. Specifically, for the file requests cannot be served by any cache nodes, the constraint (3) in the revised manuscript makes sure that the requesting users can decode the files successfully in downlink multicast, i.e.,
	\begin{align}
	R_{\tau}\geq R_F, \forall \tau,
	\end{align}
	where $R_{\tau}$ denotes the maximum number of information bits that can be delivered from the BS to the $\tau$-th requesting user, and $R_F$ denotes the number of  information bits of each file. Because of the above constraint, the BS can make sure the successful file decoding at the requesting users, even if we minimize the transmission resources at the BS. 
	
From a higher-level point of view, we considered the optimization in the following scenario. 

\begin{itemize}

\item In a finite lifetime,  users arrive randomly to request popular files. 

\item If the requesting users can be served by some cache nodes (traffic offloading), the BS will not transmit to them. 

\item On the other hand, if the requesting users cannot be served by any cache node, {\bf the BS should make sure the requesting users are able to decode the files in downlink}. The downlink transmission is multicast. Hence, some cache nodes may also decode the files.




\end{itemize}


In the above scenario, we would like to minimize the average transmission resource consumption at the BS, with the constraint that the requesting users should decode the files from either BS or cache nodes. The main dynamics we can exploit is the receiving cache nodes in each BS's multicast.

The main motivation to minimize the transmission resource consumption for popular files at the BS is as follows. In practice, there are various traffic types at the BS, like popular file transmission and dedicated data unicast. Minimizing the transmission resource consumption for popular files at the BS can (1) leave more transmission resource to other traffic types; (2) achieve the purpose of green communications.

		
		We have added the abovementioned higher-level description of the problem at the end of Section III-A.
	
}
\spaceblank
\noindent{\em \textbf{Comment 4:}
	For all performance metrics that you want to use (hitting rate, etc), please introduce them at the
	end of Section II or in Section III.A and discuss them upfront.
}

\spaceblank

{\blue \textbf{Response E-4:} 
	Thank you for the comment. As defined in Section III-A, we use the average of the weighted summation of transmission power and transmission symbol number for all the BS's file multicasts as the objective. Notice that the hitting rate is not a metric in our problem formulation and solution. It is shown in the simulation section to demonstrate some side effects of different scheduling schemes. We think it might be better to introduce and discuss it at the simulation section for the ease of reading. 
	
	Specifically, in order to elaborate the definition of hitting rate, we first list the following notations.
	\begin{itemize} 
		\item 	 $ \mathcal{C}_{f,\tau} = \bigcup\limits_{\{c|\forall\mathcal{B}_{f,\tau}^c=1\}} \mathcal{C}_c $ is the coverage area of the cache nodes which have already decoded the $f$-th file before the $\tau$-th file request;
		\item $ \mathbf{l}_{\tau} $ is the location of the $\tau$-th user, $\mathcal{A}_{\tau}$ is the file index of the $\tau$-th request;
		\item $N_R$ is the number of file requests in the lifetime.
		\end{itemize}
	Given the scheduling policy $\Omega$, the hitting rate illustrated in the simulation section is defined as
	\begin{align}
	\text{Hitting rate}\triangleq\mathbb{E}_{\{S_{\tau}|\forall \tau\},N_R}^{\Omega}\bigg[\frac{1}{N_R}\sum_{\tau=1}^{N_R}\mathbf{I}  [\mathbf{l}_{\tau} \in \mathcal{C}_{\mathcal{A}_{\tau},\tau}]\bigg],
	\end{align}
	where $\mathbf{I}[.]$ is the indicator function.
	
	We have included the above definition of hitting rate in the Section VI of the revised manuscript, followed by the discussion on it. As illustrated in Fig. 5 (b) of the revised manuscript, the proposed scheme does not have the maximum hitting rate, although it has the minimum average transmission cost, when compared with other baseline schemes. In fact, the BS should multicast the popular file to as many cache nodes as possible, in order to have a high hitting rate. This may waste the transmission resource, especially with finite popularity lifetime. Hence, maximizing the hitting rate is not a good strategy if the concern is average transmission cost of the BS.
}

\spaceblank

\section{Response to Reviewer 2}
\noindent{\em Most of my previous comments have been addressed.
}

\spaceblank
{\blue
We thank the reviewer 2 for the previous constructive comments, which have helped to improve the quality of this manuscript. We now address the new comments in detail below.
}


\spaceblank
\noindent{\em \textbf{Comment 1:}  However, for the assumption that the path loss
	e.t.c. are quasi-static within one file transmission, and change independently and identically over
	different transmissions, the authors only explained the first part of this assumption. The second part
	(change independently and identically over different transmissions) is not well justified. The second
	part requires that the coherence time of the path loss is almost the same as the file transmission time,
	such that the path loss is approximately constant within one file transmission, but changes
	independently to another realization whenever a file transmission is completed. In practice, the path
	loss can be highly correlated over two consecutive file transmissions.
}
\spaceblank	

{\blue \textbf{Response R2-1:} Thank you for the comment. There might be some misunderstanding on the scenario of this work. 
	In fact, we assume new users arrive randomly to request popular files, 
		the $\tau$-th and the $(\tau+1)$-th file requests do not come from
		the same user. Hence, it is not necessary to assume pathloss correlation between two consecutive file transmissions. 
		Note that the i.i.d. distribution of requesting users
		 is a common assumption made on cache-enabled system design as in \cite{Choi2016,Cui2016-TWC-july,Cui2017-TWC}.

}

	


\spaceblank


	 


\begin{figure}[tb]
	\centering
	\includegraphics[scale = 0.72]{cost_pr.eps} %delay_cdf
	\caption{Cumulative distribution function (CDF) of the number of transmission symbols per file request when $\beta T=100$, $\gamma=1$ and $\frac{M_c}{M_F}=0.6$ ($\forall c$).}
	\label{fig:delay}
\end{figure}

	
\section{Response to Reviewer 3}
\noindent{\em Thanks for solving most of my comments.
	}


\spaceblank
{\blue
	We are thankful to Reviewer 3 for the previous constructive and positive comments, which have helped to improve the quality of the manuscript. We now address the new comments below.
}



\spaceblank
\noindent{\em \textbf{Comment 1:} 
However, basic features / metrics of wireless performance,
such as delay, number of users (as multi-cast is considered), are still needed.
}



\spaceblank	
{\blue \textbf{Response R3-1:} 
	 Thank you for the comment. In fact, we do not consider or optimize the delay performance in this work. The delay performance depends on the frame-level scheduling and load of all traffic types (including popular file transmission, dedicated data transmission and etc.), and we consider the scheduling in a larger granularity (i.e., file-level scheduling). Instead, in Fig. \ref{fig:delay}, the distribution of transmission symbol number
	 for each file multicast is illustrated, where the file delivery via cache nodes consumes zero downlink transmission symbol.
	  It can be observed that the proposed scheme uses less transmission symbols in general, compared with other schemes. 
	  As a result, the BS has better potential to achieve smaller transmission delay for all types of traffics with the proposed scheme.
	 Due to the page limitation, Fig. 2 is not added into the revised manuscript.
	 % We have added Fig. \ref{fig:delay} and the discussion on it into the revised manuscript.
	 
	Moreover, please refer to the Response E-3.1 for the discussion on the average cost versus the average requesting user number in the lifetime.

 
	 
}



\bibliographystyle{IEEEtran}
\bibliography{Cache2_Minor}		
\end{document}